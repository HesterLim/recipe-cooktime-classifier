{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create URL\n",
    "test_csv_2 = \"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_test.csv\"\n",
    "train_csv_2 = \"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_train.csv\"\n",
    "\n",
    "# Load Dataset \n",
    "test_df = pd.read_csv(test_csv_2)\n",
    "train_df = pd.read_csv(train_csv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[['n_steps', 'n_ingredients']]\n",
    "y = train_df['duration_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "X_train_name = scipy.sparse.load_npz('C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_countvec\\\\train_name_vec.npz')\n",
    "X_test_name = scipy.sparse.load_npz('C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_countvec\\\\test_name_vec.npz')\n",
    "\n",
    "X_train_step = scipy.sparse.load_npz('C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_countvec\\\\train_steps_vec.npz')\n",
    "X_test_step = scipy.sparse.load_npz('C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_countvec\\\\test_steps_vec.npz')\n",
    "\n",
    "X_train_ingr = scipy.sparse.load_npz('C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_countvec\\\\train_ingr_vec.npz')\n",
    "X_test_ingr = scipy.sparse.load_npz('C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_countvec\\\\test_ingr_vec.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "name_vectorizer = pickle.load(open(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_countvec\\\\train_name_countvectorizer.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features with CountVec and Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection with Mutual Information for 'name'\n",
    "k = 1000\n",
    "mi = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "name_train_mi = mi.fit_transform(X_train_name,y)\n",
    "name_test_mi = mi.transform(X_test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection with Mutual Information for 'steps'\n",
    "mi = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "step_train_mi = mi.fit_transform(X_train_step,y)\n",
    "step_test_mi = mi.transform(X_test_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection with Mutual Information for 'ingr'\n",
    "mi = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "ingr_train_mi = mi.fit_transform(X_train_ingr,y)\n",
    "ingr_test_mi = mi.transform(X_test_ingr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Features for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = train_df.copy()\n",
    "new_train_df = new_train_df[['n_steps','n_ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_matrix = name_train_mi.todense()\n",
    "name_list = name_matrix.tolist()\n",
    "name_df = pd.DataFrame(name_list)\n",
    "name_df = name_df.add_prefix('name_')\n",
    "\n",
    "step_matrix = step_train_mi.todense()\n",
    "step_list = step_matrix.tolist()\n",
    "step_df = pd.DataFrame(step_list)\n",
    "step_df = step_df.add_prefix('step_')\n",
    "\n",
    "ingr_matrix = ingr_train_mi.todense()\n",
    "ingr_list = ingr_matrix.tolist()\n",
    "ingr_df = pd.DataFrame(ingr_list)\n",
    "ingr_df = ingr_df.add_prefix('ingr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add name, step and ingr from countvec to new_train_df, name the df features_train\n",
    "features_train = new_train_df.join(name_df)\n",
    "features_train = features_train.join(step_df)\n",
    "features_train = features_train.join(ingr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec_train = features_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = test_df.copy()\n",
    "new_test_df = new_test_df[['n_steps','n_ingredients']]\n",
    "\n",
    "name_matrix_test = name_test_mi.todense()\n",
    "name_list_test = name_matrix_test.tolist()\n",
    "name_df_test = pd.DataFrame(name_list_test)\n",
    "name_df_test = name_df_test.add_prefix('name_')\n",
    "\n",
    "step_matrix_test = step_test_mi.todense()\n",
    "step_list_test = step_matrix_test.tolist()\n",
    "step_df_test = pd.DataFrame(step_list_test)\n",
    "step_df_test = step_df_test.add_prefix('step_')\n",
    "\n",
    "ingr_matrix_test = ingr_test_mi.todense()\n",
    "ingr_list_test = ingr_matrix_test.tolist()\n",
    "ingr_df_test = pd.DataFrame(ingr_list_test)\n",
    "ingr_df_test = ingr_df_test.add_prefix('ingr_')\n",
    "\n",
    "# Add name, step and ingr from countvec to new_test_df, name the df features_test\n",
    "features_test = new_test_df.join(name_df_test)\n",
    "features_test = features_test.join(step_df_test)\n",
    "features_test = features_test.join(ingr_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec100 (does not increase accuracy, leave it out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Doc2Vec100 Dataset \n",
    "train_name_doc100 = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec100\\\\recipe_text_features_doc2vec100\\\\train_name_doc2vec100.csv\", header=None)\n",
    "test_name_doc100 = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec100\\\\recipe_text_features_doc2vec100\\\\test_name_doc2vec100.csv\", header=None)\n",
    "train_steps_doc100 = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec100\\\\recipe_text_features_doc2vec100\\\\train_steps_doc2vec100.csv\", header=None)\n",
    "test_steps_doc100 = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec100\\\\recipe_text_features_doc2vec100\\\\test_steps_doc2vec100.csv\", header=None)\n",
    "train_ingr_doc100 = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec100\\\\recipe_text_features_doc2vec100\\\\train_ingr_doc2vec100.csv\", header=None)\n",
    "test_ingr_doc100 = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec100\\\\recipe_text_features_doc2vec100\\\\test_ingr_doc2vec100.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all Doc2Vec data to features_train, name the new df \"features_train_doc100\"\n",
    "train_name_doc100 = train_name_doc100.add_suffix('name_doc2vec')\n",
    "feature_train_doc100 = features_train.join(train_name_doc100)\n",
    "train_steps_doc100 = train_steps_doc100.add_suffix('step_doc2vec')\n",
    "feature_train_doc100 = feature_train_doc100.join(train_steps_doc100)\n",
    "train_ingr_doc100 = train_ingr_doc100.add_suffix('ingr_doc2vec')\n",
    "feature_train_doc100 = feature_train_doc100.join(train_ingr_doc100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all Doc2Vec data to features_test, name the new df \"features_test_doc100\"\n",
    "test_name_doc100 = test_name_doc100.add_suffix('name_doc2vec')\n",
    "feature_test_doc100 = features_test.join(test_name_doc100)\n",
    "test_steps_doc100 = test_steps_doc100.add_suffix('step_doc2vec')\n",
    "feature_test_doc100 = feature_test_doc100.join(test_steps_doc100)\n",
    "test_ingr_doc100 = test_ingr_doc100.add_suffix('ingr_doc2vec')\n",
    "feature_test_doc100 = feature_test_doc100.join(test_ingr_doc100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Doc2Vec50 Dataset \n",
    "train_name_tot = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec50\\\\recipe_text_features_doc2vec50\\\\train_name_doc2vec50.csv\", header=None)\n",
    "test_name_tot = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec50\\\\recipe_text_features_doc2vec50\\\\test_name_doc2vec50.csv\", header=None)\n",
    "train_steps_tot = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec50\\\\recipe_text_features_doc2vec50\\\\train_steps_doc2vec50.csv\", header=None)\n",
    "test_steps_tot = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec50\\\\recipe_text_features_doc2vec50\\\\test_steps_doc2vec50.csv\", header=None)\n",
    "train_ingr_tot = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec50\\\\recipe_text_features_doc2vec50\\\\train_ingr_doc2vec50.csv\", header=None)\n",
    "test_ingr_tot = pd.read_csv(\"C:\\\\Users\\\\kenne\\\\recipe-cooktime-predictor data\\\\COMP30027_2021_Project2_datasets\\\\recipe_text_features_doc2vec50\\\\recipe_text_features_doc2vec50\\\\test_ingr_doc2vec50.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all Doc2Vec50 data to features_train, name the new df \"features_train_tot\"\n",
    "train_name_tot = train_name_tot.add_suffix('name_doc2vec_50')\n",
    "feature_train_tot = features_train.join(train_name_tot)\n",
    "train_steps_tot = train_steps_tot.add_suffix('step_doc2vec_50')\n",
    "feature_train_tot = feature_train_tot.join(train_steps_tot)\n",
    "train_ingr_tot = train_ingr_tot.add_suffix('ingr_doc2vec_50')\n",
    "feature_train_tot = feature_train_tot.join(train_ingr_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all Doc2Vec50 data to features_test, name the new df \"features_test_tot\"\n",
    "test_name_tot = test_name_tot.add_suffix('name_doc2vec_50')\n",
    "feature_test_tot = features_test.join(test_name_tot)\n",
    "test_steps_tot = test_steps_tot.add_suffix('step_doc2vec_50')\n",
    "feature_test_tot = feature_test_tot.join(test_steps_tot)\n",
    "test_ingr_tot = test_ingr_tot.add_suffix('ingr_doc2vec_50')\n",
    "feature_test_tot = feature_test_tot.join(test_ingr_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into train and test set\n",
    "X_train_tot_split, X_test_tot_split, y_train_tot_split, y_test_tot_split = train_test_split(feature_train_tot, y, test_size=0.33, random_state=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression(C=0.01, solver='sag')\n",
    "lgr.fit(feature_train_tot, y)\n",
    "ybar = lgr.predict(feature_test_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8253787878787879\n",
      "f1 score: 0.8253787878787879\n"
     ]
    }
   ],
   "source": [
    "test_id = test_df.index\n",
    "data = {'id': test_id+1, 'duration_label': ybar}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('predict.csv', index=False)\n",
    "acc = lgr.score(X_test_tot_split, y_test_tot_split)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lgr.predict(X_test_tot_split)\n",
    "print(\"f1 score:\", f1_score(y_test_tot_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(countvec_train, y, test_size=0.33, random_state=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Features with Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "k=10\n",
    "x2 = SelectKBest(chi2, k=k)\n",
    "x2.fit(name_df,y)\n",
    "X_train_x2 = x2.transform(name_df)\n",
    "X_test_x2 = x2.transform(name_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.549675\n",
      "f1 score: 0.549675\n",
      "1995\n",
      "abaco\n",
      "acadia\n",
      "afghani\n",
      "aigo\n",
      "ail\n",
      "badun\n",
      "balsalmic\n",
      "banana\n",
      "bashed\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train_x2, y)\n",
    "acc = lgr.score(X_train_x2, y)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lgr.predict(X_train_x2)\n",
    "print(\"f1 score:\", f1_score(y, y_pred, average='micro'))\n",
    "\n",
    "for feat_num in x2.get_support(indices=True):\n",
    "    print(name_vectorizer.get_feature_names()[feat_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Features with Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1000\n",
    "mi = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "mi.fit(name_df,y)\n",
    "X_train_mi = mi.transform(name_df)\n",
    "X_test_mi = mi.transform(name_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.721175\n",
      "f1 score: 0.721175\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train_mi, y)\n",
    "acc = lgr.score(X_train_mi, y)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lgr.predict(X_train_mi)\n",
    "print(\"f1 score:\", f1_score(y, y_pred, average='micro'))\n",
    "\n",
    "for feat_num in mi.get_support(indices=True):\n",
    "    print(name_vectorizer.get_feature_names()[feat_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation - Holdout or Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7999242424242424\n",
      "f1 score: 0.7999242424242424\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train_split, y_train_split)\n",
    "acc = lgr.score(X_test_split, y_test_split)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lgr.predict(X_test_split)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7793181818181819\n",
      "f1 score: 0.7999242424242424\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train_split, y_train_split)\n",
    "acc = np.mean(cross_val_score(lgr, X_test_split, y_test_split, cv=5))\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lgr.predict(X_test_split)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both Holdout and Cross-validation get similar accuracy score. However, holdout is significantly faster than cross validation and for this reason, holdout strategy will be chosen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB Accuracy: 0.36984848484848487\n",
      "f1 score: 0.36984848484848487 \n",
      "\n",
      "5-nearest neighbour Accuracy: 0.7174242424242424\n",
      "f1 score: 0.7174242424242424 \n",
      "\n",
      "Decision Tree Accuracy: 0.7272727272727273\n",
      "f1 score: 0.7272727272727273 \n",
      "\n",
      "One_R Accuracy: 0.6552272727272728\n",
      "f1 score: 0.6552272727272728 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Construct different models \"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "models = [GaussianNB(),\n",
    "          KNeighborsClassifier(n_neighbors=5),\n",
    "          DecisionTreeClassifier(max_depth=None),\n",
    "          DecisionTreeClassifier(max_depth=1)]\n",
    "titles = ['GNB',\n",
    "          '5-nearest neighbour',\n",
    "          'Decision Tree',\n",
    "          'One_R']\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    model.fit(X_train_split,y_train_split)\n",
    "    acc = model.score(X_test_split,y_test_split)\n",
    "    print(title, \"Accuracy:\",acc)\n",
    "    y_pred = model.predict(X_test_split)\n",
    "    print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Accuracy: 0.7999242424242424\n",
      "f1 score: 0.7999242424242424\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Compare LogisticRegression model to other models above \"\"\"\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train_split,y_train_split)\n",
    "acc = log.score(X_test_split,y_test_split)\n",
    "print(\"LogisticRegression Accuracy:\",acc)\n",
    "y_pred = lgr.predict(X_test_split)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking, Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Ensemble model \"\"\"\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "class StackingClassifier():\n",
    "\n",
    "    def __init__(self, classifiers, metaclassifier):\n",
    "        self.classifiers = classifiers\n",
    "        self.metaclassifier = metaclassifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for clf in self.classifiers:\n",
    "            clf.fit(X, y)\n",
    "        X_meta = self._predict_base(X)\n",
    "        self.metaclassifier.fit(X_meta, y)\n",
    "    \n",
    "    def _predict_base(self, X):\n",
    "        yhats = []\n",
    "        for clf in self.classifiers:\n",
    "            yhat = clf.predict_proba(X)\n",
    "            yhats.append(yhat)\n",
    "        yhats = np.concatenate(yhats, axis=1)\n",
    "        assert yhats.shape[0] == X.shape[0]\n",
    "        return yhats\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_meta = self._predict_base(X)     \n",
    "        yhat = self.metaclassifier.predict(X_meta)\n",
    "        return yhat\n",
    "    def score(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        return accuracy_score(y, yhat)\n",
    "    \n",
    "\n",
    "\n",
    "classifiers = [DecisionTreeClassifier(), KNeighborsClassifier(), MultinomialNB()]\n",
    "titles = ['Decision Tree', 'KNeighborsClassifier()', 'Multinomial NB']\n",
    "\n",
    "\n",
    "\n",
    "meta_classifier_lr = LogisticRegression()\n",
    "stacker_lr = StackingClassifier(classifiers, meta_classifier_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacker Accuracy: 0.7265151515151516\n",
      "f1 score: 0.7265151515151516\n"
     ]
    }
   ],
   "source": [
    "stacker_lr.fit(X_train_split, y_train_split)\n",
    "acc = stacker_lr.score(X_test_split, y_test_split)\n",
    "print(\"Stacker Accuracy:\",acc)\n",
    "y_pred = stacker_lr.predict(X_test_split)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.504440\n",
       "1    0.443657\n",
       "3    0.051903\n",
       "Name: duration_label, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dataset is balanced or not? \n",
    "y_train_imbalance = y_train_split.astype(int)\n",
    "y_train_imbalance.value_counts()/y_train_split.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7828030303030303\n",
      "f1 score: 0.7828030303030302\n"
     ]
    }
   ],
   "source": [
    "# Basic Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg2 = LogisticRegression(class_weight='balanced') # inverse class weighting to reduce bias\n",
    "lg2.fit(X_train_split,y_train_split)\n",
    "\n",
    "acc = lg2.score(X_test_split, y_test_split)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lg2.predict(X_test_split)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing features - binary logistic regression requires the dependent variable to be binary and ordinal logistic regression requires the dependent variable to be ordinal.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train_split)\n",
    "X_train_scaled = scaler.transform(X_train_split)\n",
    "X_test_scaled = scaler.transform(X_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7834848484848485\n",
      "f1 score: 0.7834848484848485\n"
     ]
    }
   ],
   "source": [
    "# Does Scaling + fix class imbalance + use a faster solve improve performance?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg2 = LogisticRegression(class_weight='balanced', solver = \"sag\") # inverse class weighting to reduce bias, solve faster\n",
    "lg2.fit(X_train_scaled,y_train_split)\n",
    "\n",
    "acc = lg2.score(X_test_scaled, y_test_split)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lg2.predict(X_test_scaled)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does Scaling improve performance?  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train_scaled, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7771969696969697\n",
      "f1 score: 0.7771969696969697\n"
     ]
    }
   ],
   "source": [
    "acc = lgr.score(X_test_scaled, y_test_split)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lgr.predict(X_test_scaled)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling does not seem to improve the performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA - Reducing Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 3002\n",
      "Reduced number of features: 2724\n"
     ]
    }
   ],
   "source": [
    "# Third, logistic regression requires there to be little or no multicollinearity among the independent variables. This means that the independent variables should not be too highly correlated with each other.\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA that will retain 99% of variance \n",
    "pca = PCA(n_components=0.99, whiten = True)\n",
    "\n",
    "# Conduct PCA\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Show results \n",
    "print(\"Original number of features:\", X_train_scaled.shape[1])\n",
    "print(\"Reduced number of features:\", X_train_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct PCA from fitted set\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does PCA improve performance? \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train_pca, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7713636363636364\n",
      "f1 score: 0.7713636363636364\n"
     ]
    }
   ],
   "source": [
    "acc = lgr.score(X_test_pca, y_test_split)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lgr.predict(X_test_pca)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7748484848484849\n",
      "f1 score: 0.7748484848484849\n"
     ]
    }
   ],
   "source": [
    "# Does PCA + fix class imbalance + use a faster solve improve performance + reduce correlation? \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg2 = LogisticRegression(class_weight='balanced', solver = \"sag\") # inverse class weighting to reduce bias, solve faster\n",
    "lg2.fit(X_train_pca,y_train_split)\n",
    "\n",
    "acc = lg2.score(X_test_pca, y_test_split)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lg2.predict(X_test_pca)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7999242424242424\n",
      "f1 score: 0.7999242424242424\n"
     ]
    }
   ],
   "source": [
    "lg1 = LogisticRegression()\n",
    "lg1.fit(X_train_split, y_train_split)\n",
    "acc = lg1.score(X_test_split, y_test_split)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lg1.predict(X_test_split)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8033333333333333\n",
      "f1 score: 0.8033333333333333\n"
     ]
    }
   ],
   "source": [
    "lg2 = LogisticRegression(C=0.1, solver='sag')\n",
    "lg2.fit(X_train_split, y_train_split)\n",
    "acc = lg2.score(X_test_split, y_test_split)\n",
    "print(\"Accuracy:\",acc)\n",
    "y_pred = lg2.predict(X_test_split)\n",
    "print(\"f1 score:\", f1_score(y_test_split, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg3 = LogisticRegression(C=1.0, solver='sag', max_iter = 2000)\n",
    "lg3.fit(X_train_tot_split, y_train_tot_split)\n",
    "ybar = lg3.predict(feature_test_tot)\n",
    "test_id = test_df.index\n",
    "data = {'id': test_id+1, 'duration_label': ybar}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('test3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "lg4 = LogisticRegression(C=0.001, solver='sag')\n",
    "lg4.fit(X_train_tot_split, y_train_tot_split)\n",
    "ybar = lg4.predict(feature_test_tot)\n",
    "test_id = test_df.index\n",
    "data = {'id': test_id+1, 'duration_label': ybar}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('tot_0_001_sag.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "lgr5 = LogisticRegression(C=1.0, solver='saga')\n",
    "lgr5.fit(feature_train_tot, y)\n",
    "ybar = lgr5.predict(feature_test_tot)\n",
    "test_id = test_df.index\n",
    "data = {'id': test_id+1, 'duration_label': ybar}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('newt_tot.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kenne\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression(C=0.01, solver='sag')\n",
    "lgr.fit(X_train_split, y_train_split)\n",
    "ybar = lgr.predict(X_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {'Predicted labels': ybar, 'Actual labels':y_test_split}\n",
    "pred_df = pd.DataFrame(pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cf = confusion_matrix(y_test_split, ybar)\n",
    "sns.heatmap(cf, annot=True, fmt=\"d\", cmap=\"YlGnBu\", xticklabels=[1, 2, 3], yticklabels=[1, 2, 3])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "wrong_dict = {1.0:0, 2.0:0, 3.0:0}\n",
    "while i < len(pred_df):\n",
    "    pred = pred_df['Predicted labels'].iloc[i]\n",
    "    actual = pred_df['Actual labels'].iloc[i]\n",
    "    if pred != actual:\n",
    "        wrong_dict[actual] += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 1006, 2.0: 1315, 3.0: 265}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbCUlEQVR4nO3de5gdVZnv8e+PhDsh4dIyMRcSNUeGQUCmRRiOXA/IRRJkEGFEAvKQ8QxKGFCJKILDqOEoFzOODBlBwwwDInIJGMUQkiAqlyQwgSQw9HCRxECiXJKAAULe+aNWw05O965Kumvv6uzf53nq2VWratd6d+/n2W+vWlVrKSIwMzOrZ7NmB2BmZtXnZGFmZrmcLMzMLJeThZmZ5XKyMDOzXP2bHUAZdt555xgxYkSzwzAz61Pmzp37h4ho62rfJpksRowYwZw5c5odhplZnyLp2e72+TKUmZnlcrIwM7NcThZmZpbLycLMzHI5WZiZWS4nCzMzy+VkYWZmuZwszMwsl5OFmZnl2iSf4LbWMmLCz5odwibrmYnHNDsEqwi3LMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVkuJwszM8vlZGFmZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVmu0pKFpGslLZP0WE3ZtyU9Lmm+pFslDarZ92VJHZKekPTRmvIjU1mHpAllxWtmZt0rs2XxI+DI9cqmA3tExJ7AfwFfBpC0O3AS8BfpPd+X1E9SP+CfgaOA3YGT07FmZtZApSWLiLgXeHG9sl9GxJq0eT8wNK2PAW6MiNcj4mmgA9g3LR0R8VREvAHcmI41M7MGamafxWeAn6f1IcBzNfsWp7Luyv8/ksZJmiNpzvLly0sI18ysdTUlWUj6CrAGuL63zhkRkyOiPSLa29raeuu0ZmZGE+bglnQa8DHgsIiIVLwEGFZz2NBURp1yMzNrkIa2LCQdCXwJGB0Rr9XsmgqcJGlLSSOBUcCDwEPAKEkjJW1B1gk+tZExm5lZiS0LSTcABwM7S1oMXER299OWwHRJAPdHxGcjYoGkm4CFZJenzoqIt9J5PgfcBfQDro2IBWXFbGZmXSstWUTEyV0UX1Pn+G8A3+iifBowrRdDMzOzDeQnuM3MLJeThZmZ5XKyMDOzXLnJQtJ7JW2Z1g+WdHbtmE5mZrbpK9Ky+CnwlqT3AZPJnnv4j1KjMjOzSimSLNam8Zw+DvxTRHwRGFxuWGZmViVFksWbkk4GxgJ3prLNywvJzMyqpkiyOB3YH/hGRDydnrD+t3LDMjOzKsl9KC8iFgJn12w/DVxaZlBmZlYtuclC0gHAxcCu6XgBERHvKTc0MzOriiLDfVwD/D0wF3ir3HDMzKyKiiSLVyLi5/mHmZnZpqpIspgp6dvALcDrnYURMa+0qMzMrFKKJIsPp9f2mrIADu39cMzMrIqK3A11SCMCMTOz6ioyNtRASZdLmpOWyyQNbERwZmZWDUUeyrsWWAmcmJYVwA/LDMrMzKqlSJ/FeyPir2u2vy7pkZLiMTOzCirSsviTpP/duZEe0vtTeSGZmVnVFGlZ/F9gSuqnEPAicFqZQZmZWbUUuRvqEWAvSdun7RVlB2VmZtXSbbKQdEpE/Lukc9crByAiLi85NjMzq4h6fRbbptcBXSzb5Z1Y0rWSlkl6rKZsR0nTJT2ZXndI5ZI0SVKHpPmS9ql5z9h0/JOSxm7EZzQzsx7qtmUREVen1bsj4te1+1Ind54fAd8DrqspmwDMiIiJkiak7fOBo4BRafkwcBXwYUk7AheRPT0ewFxJUyPipQL1m5lZLynSwf1PwD4FytYREfdKGrFe8Rjg4LQ+BZhFlizGANdFRAD3SxokaXA6dnpEvAggaTpwJHBDgbg32ogJPyvz9C3tmYnHNDsEM9sI9fos9gf+Cmhbr99ie6DfRta3S0QsTevPA7uk9SHAczXHLU5l3ZV3Fe84YBzA8OHDNzI8MzPrSr0+iy3I+ib6s25/xQrghJ5WnFoR0dPz1JxvckS0R0R7W1tbb53WzMyo32cxG5gt6UcR8Wwv1feCpMERsTRdZlqWypcAw2qOG5rKlvDOZavO8lm9FIuZmRVU5AnuH0ga1LkhaQdJd21kfVOBzjuaxgK315Sfmu6K2o9swqWlwF3AEanOHYAjUpmZmTVQkQ7unSPi5c6NiHhJ0rvy3iTpBrJWwc6SFpPd1TQRuEnSGcCzZAMTAkwDjgY6gNeA01NdL0q6BHgoHfcPnZ3dZmbWOEWSxVpJwyPidwCSdqVAX0NEnNzNrsO6ODaAs7o5z7VkI9+amVmTFEkWXwHukzSbbGyoj5DuOjIzs9ZQZGyoX6QnqvdLRedExB/KDcvMzKqk2w5uSbul132A4cDv0zK8djgOMzPb9NVrWZwHnAlc1sW+AA4tJSIzM6uces9ZnJleD2lcOGZmVkX1hvs4vt4bI+KW3g/HzMyqqN5lqGPT67vIxoi6J20fAvwGcLIwM2sR9S5DnQ4g6ZfA7p0DAKZhOn7UkOjMzKwSigz3MaxmpFiAF8jujjIzsxZR5KG8GWksqM45JD4J3F1eSGZmVjVFHsr7nKSPAwemoskRcWu5YZmZWZUUaVkAzANWRsTdkraRNCAiVpYZmJmZVUdun4WkM4Gbgc45uYcAt5UYk5mZVUyRDu6zgAPIZsgjIp4ku53WzMxaRJFk8XpEvNG5Iak/vTgdqpmZVV+RZDFb0gXA1pIOB34C3FFuWGZmViVFksX5wHLgUeBvyWa1+2qZQZmZWbXUvRtKUj9gQUTsBvxrY0IyM7OqqduyiIi3gCck+YltM7MWVuQ5ix2ABZIeBF7tLIyI0aVFZWZmlVIkWVxYehRmZlZp9eaz2Ar4LPA+ss7tayJiTaMCMzOz6qjXZzEFaCdLFEfR9fSqZmbWAuoli90j4pSIuBo4AfhIb1Uq6e8lLZD0mKQbJG0laaSkByR1SPqxpC3SsVum7Y60f0RvxWFmZsXUSxZvdq705uUnSUOAs4H2iNgD6AecBFwKXBER7wNeAs5IbzkDeCmVX5GOMzOzBqqXLPaStCItK4E9O9clrehhvf3JngjvD2wDLAUOJRuwELJLYMel9TFpm7T/MEnqYf1mZrYB6k2r2q+MCiNiiaTvAL8D/gT8EpgLvFzTgllMNrot6fW59N41kl4BdgL+UHteSeOAcQDDh/uxEDOz3lRkuI9eJWkHstbCSODdwLbAkT09b0RMjoj2iGhva2vr6enMzKxGw5MF8H+ApyNieUS8CdxCNgT6oHRZCmAosCStLwGGwdsj3g4E/tjYkM3MWlszksXvgP3SjHsCDgMWAjPJ7roCGAvcntanpm3S/nsiwkOkm5k1UMOTRUQ8QNZRPY/sGY7NgMlko9ueK6mDrE/imvSWa4CdUvm5wIRGx2xm1upyh/tId0Kt/5/8K8Ac4LyIeGpDK42Ii4CL1it+Cti3i2NXA5/Y0DrMzKz3FBkb6kqyu5P+AxDZMxHvJWsZXAscXFJsZmZWEUUuQ42OiKsjYmVErIiIycBHI+LHZCPSmpnZJq5IsnhN0omSNkvLicDqtM8dzWZmLaBIsvgU8GlgGfBCWj9F0tbA50qMzczMKiK3zyJ1YB/bze77ejccMzOroiJ3Q7UBZwIjao+PiM+UF5aZmVVJkbuhbgd+BdwNvFVuOGZmVkVFksU2EXF+6ZGYmVllFengvlPS0aVHYmZmlVUkWYwnSxir01wWvTGfhZmZ9SFF7oYa0IhAzMysuor0WSBpNHBg2pwVEXeWF5KZmVVN7mUoSRPJLkUtTMt4Sd8qOzAzM6uOIi2Lo4G9I2ItgKQpwMPAl8sMzMzMqqPofBaDatYHlhCHmZlVWJGWxTeBhyXNJBui/EA8AZGZWUupmywkbQasBfYDPpSKz4+I58sOzMzMqqNusoiItZK+FBE3kc2FbWZmLahIn8Xdkr4gaZikHTuX0iMzM7PKKNJn8cn0elZNWQDv6f1wzMysirpNFpKOA34TESMbF46ZmVVRvctQp5DdBfWkpCmSxknao1GBmZlZdXSbLCLihIgYAhwB3AXsCUyRtFzStJ5UKmmQpJslPS5pkaT9U1/I9JScpkvaIR0rSZMkdUiaL2mfntRtZmYbLreDOyKeBuaRPbX9CNlc3Fv3sN7vAr+IiN2AvYBFZM9uzIiIUcAM3nmW4yhgVFrGAVf1sG4zM9tA9fosLgD2B9qAJ4D7ge8B4yJio2fMkzSQ7MG+0wAi4g3gDUljgIPTYVOAWcD5wBjguogI4P7UKhkcEUs3NgYzM9sw9e6GOhV4FbgD+A3wQES80gt1jgSWAz+UtBcwl2ygwl1qEsDzwC5pfQjwXM37F6eydZKFpHFkLQ+GDx/eC2GamVmnen0WuwGHA3PI/uO/VdKDkv5V0uk9qLM/sA9wVUR8kCwhrTN8SGpFxIacNCImR0R7RLS3tbX1IDwzM1tf3T6LiHgxzV3xNbJRZn8CHAL8oAd1LgYWR8QDaftmsuTxgqTBAOl1Wdq/BBhW8/6hqczMzBqk22QhabSkiZJ+RfbD/R1gJ+A84M82tsI0rtRzkt6fig4jmydjKjA2lY0Fbk/rU4FT011R+wGvuL/CzKyx6vVZnAb8GvgSMDd1RPeWzwPXS9oCeAo4nSxx3STpDOBZ4MR07DSyOTU6gNfSsWZm1kDdJouIOL6sSiPiEaC9i12HdXFssO5QI2Zm1mBFJz8yM7MW5mRhZma56nVwz0ivlzYuHDMzq6J6HdyDJf0VMFrSjWRTqr4tIuaVGpmZmVVGvWTxNeBCsucaLl9vXwCHlhWUmZlVS727oW4GbpZ0YURc0sCYzMysYnJnyouISySNJhv8D2BWeqrbzMxaRO7dUJK+RTbQ38K0jJf0zbIDMzOz6igyB/cxwN4RsRZA0hSyuS0uKDMwMzOrjqLPWQyqWR9YQhxmZlZhRVoW3yKbi3sm2e2zB7LekOJmZrZpK9LBfYOkWcCHUtH5aeRYMzNrEUVaFqQhwaeWHIuZmVWUx4YyM7NcThZmZparbrKQ1E/S440KxszMqilvDu63gCckDW9QPGZmVkFFOrh3ABZIehB4tbMwIkaXFpWZmVVKkWRxYelRmJlZpRV5zmK2pF2BURFxt6RtgH7lh2ZmZlVRZCDBM4GbgatT0RDgthJjMjOziily6+xZwAHACoCIeBJ4V5lBmZlZtRRJFq9HxBudG5L6k82UZ2ZmLaJIspgt6QJga0mHAz8B7uhpxekZjocl3Zm2R0p6QFKHpB9L2iKVb5m2O9L+ET2t28zMNkyRZDEBWA48CvwtMA34ai/UPR5YVLN9KXBFRLwPeAk4I5WfAbyUyq9Ix5mZWQPlJos06dEU4BLg68CUiOjRZShJQ8kmVfpB2hZwKFlHOqm+49L6mLRN2n9YOt7MzBqkyN1QxwD/DUwCvgd0SDqqh/VeCXwJWJu2dwJejog1aXsx2V1XpNfnANL+V9Lx68c5TtIcSXOWL1/ew/DMzKxWkctQlwGHRMTBEXEQcAjZ5aCNIuljwLKImLux5+hKREyOiPaIaG9ra+vNU5uZtbwiT3CvjIiOmu2ngJU9qPMAYLSko4GtgO2B7wKDJPVPrYehwJJ0/BJgGLA43Yk1EPhjD+o3M7MN1G3LQtLxko4H5kiaJuk0SWPJ7oR6aGMrjIgvR8TQiBgBnATcExGfAmYCJ6TDxgK3p/WpaZu0/56e9pmYmdmGqdeyOLZm/QXgoLS+HNi6hFjOB26U9I/Aw8A1qfwa4N8kdQAvkiUYMzNroG6TRUScXnblETELmJXWnwL27eKY1cAnyo7FzMy6l9tnIWkk8HlgRO3xHqLczKx1FOngvo3sUtAdvHOrq5mZtZAiyWJ1REwqPRIzM6usIsniu5IuAn4JvN5ZGBHzSovKzMwqpUiy+ADwabLhODovQ0XaNjOzFlAkWXwCeE/tMOVmZtZaigz38RgwqOQ4zMyswoq0LAYBj0t6iHX7LHzrrJlZiyiSLC4qPQozM6u03GQREbMbEYiZmVVXkSe4V/LOnNtbAJsDr0bE9mUGZmZm1VGkZTGgcz3NUDcG2K/MoMzMrFqK3A31tsjcBny0nHDMzKyKilyGOr5mczOgHVhdWkRmZlY5Re6Gqp3XYg3wDNmlKDMzaxFF+ixKn9fCzFrLiAk/a3YIm6xnJh5Tynm7TRaSvlbnfRERl5QQj5mZVVC9lsWrXZRtC5wB7AQ4WZiZtYh606pe1rkuaQAwHjgduBG4rLv3mZnZpqdun4WkHYFzgU8BU4B9IuKlRgRmZmbVUa/P4tvA8cBk4AMRsaphUZmZWaXUeyjvPODdwFeB30takZaVklY0JjwzM6uCbpNFRGwWEVtHxICI2L5mGdCTcaEkDZM0U9JCSQskjU/lO0qaLunJ9LpDKpekSZI6JM2XtM/G1m1mZhtng4b76CVrgPMiYneyMabOkrQ7MAGYERGjgBlpG+AoYFRaxgFXNT5kM7PW1vBkERFLI2JeWl8JLAKGkD0VPiUdNgU4Lq2PAa5L41LdDwySNLixUZuZtbZmtCzeJmkE8EHgAWCXiFiadj0P7JLWhwDP1bxtcSpb/1zjJM2RNGf58uXlBW1m1oKaliwkbQf8FDgnItbpMI+I4J05NAqJiMkR0R4R7W1tbb0YqZmZNSVZSNqcLFFcHxG3pOIXOi8vpddlqXwJMKzm7UNTmZmZNUjDk0WaQOkaYFFEXF6zayowNq2PBW6vKT813RW1H/BKzeUqMzNrgCJDlPe2A4BPA49KeiSVXQBMBG6SdAbwLHBi2jcNOBroAF4jG3LEzMwaqOHJIiLuA9TN7sO6OD6As0oNyszM6mrq3VBmZtY3OFmYmVkuJwszM8vlZGFmZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVkuJwszM8vlZGFmZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVkuJwszM8vlZGFmZrmcLMzMLJeThZmZ5XKyMDOzXH0mWUg6UtITkjokTWh2PGZmraRPJAtJ/YB/Bo4CdgdOlrR7c6MyM2sdfSJZAPsCHRHxVES8AdwIjGlyTGZmLaN/swMoaAjwXM32YuDDtQdIGgeMS5urJD3RoNiabWfgD80Ooihd2uwIKqHPfGf+vt7WKt/Zrt3t6CvJIldETAYmNzuORpM0JyLamx2HFefvrO/xd9Z3LkMtAYbVbA9NZWZm1gB9JVk8BIySNFLSFsBJwNQmx2Rm1jL6xGWoiFgj6XPAXUA/4NqIWNDksKqi5S69bQL8nfU9Lf+dKSKaHYOZmVVcX7kMZWZmTeRkYWZmuZws+ihJ10paJumxZsdi+SQNkzRT0kJJCySNb3ZMVp+krSQ9KOk/03f29WbH1Ezus+ijJB0IrAKui4g9mh2P1SdpMDA4IuZJGgDMBY6LiIVNDs26IUnAthGxStLmwH3A+Ii4v8mhNYVbFn1URNwLvNjsOKyYiFgaEfPS+kpgEdnIBFZRkVmVNjdPS8v+d+1kYdZgkkYAHwQeaHIolkNSP0mPAMuA6RHRst+Zk4VZA0naDvgpcE5ErGh2PFZfRLwVEXuTjRqxr6SWveTrZGHWIOm690+B6yPilmbHY8VFxMvATODIJofSNE4WZg2QOkuvARZFxOXNjsfySWqTNCitbw0cDjze1KCayMmij5J0A/Bb4P2SFks6o9kxWV0HAJ8GDpX0SFqObnZQVtdgYKak+WTj002PiDubHFPT+NZZMzPL5ZaFmZnlcrIwM7NcThZmZpbLycLMzHI5WZiZWS4nC6sUSX8m6UZJ/y1prqRpkv5XneMHSfq7BsX2WUmn9sJ5Zklq76J8c0kTJT0paZ6k30o6aiPrWFVn3041t+8+L2lJzfa+kiZtTJ22aesT06paa0gPrt0KTImIk1LZXsAuwH9187ZBwN8B3y85tv4R8S9l1gFcQnZv/x4R8bqkXYCDeruSiPgjsDeApIuBVRHxnZpDHuztOq3vc8vCquQQ4M3aH+WI+M+I+JWk7STNSP9xPyppTDpkIvDe9F/xtwEkfVHSQ5Lm185BIOlCSU9Iuk/SDZK+kMr3lnR/Ov5WSTuk8lmSrpQ0Bxgv6eKa95yd5qaYL+nGVLZtmmfkQUkPd8YoaevUWlok6VZg6/U/uKRtgDOBz0fE6+mzvxARN6X9J6fP/ZikS2ve12V5zf6dUwvlmCJfgKSDJd2Z1i+WNEXSryQ9K+l4Sf8v1feLNHwJkv5S0uzUErwrDcdum5qI8OKlEgtwNnBFN/v6A9un9Z2BDkDACOCxmuOOACanfZsBdwIHAh8CHgG2AgYATwJfSO+ZDxyU1v8BuDKtzwK+X3Pui2ve83tgy7Q+KL1+Ezils4ysNbQtcC5wbSrfE1gDtK/3+fYEHu7ms78b+B3Qlv4O9wDHdVee3rOKrEX2AHB4nb/5258pbR8M3Fmz7z6yobn3Al4Djkr7bk0xbA78BmhL5Z/s/KxeNq3Fl6GsrxDwzTTp01qyuSB26eK4I9LycNreDhhFliBuj4jVwGpJdwBIGkj2Yz87HT8F+EnN+X7cTTzzgesl3QbcVlP36M7WB1liGk6WrCYBRMT8NHzEhvgQMCsilqeYr0/njG7KbyP7EZ8BnFXz2TbGzyPiTUmPAv2AX6TyR8kS9fuBPYDp2VVE+gFLe1CfVZSThVXJAuCEbvZ9iuw/6L9MP17PkP0Yr0/AtyLi6nUKpXM2MqZXuyk/huyH+VjgK5I+kOr+64h4Yr26i9TTAQyXtH30ztDla8hm4/so0JNk0XlJbK2kNyOic3ygtWS/HwIWRMT+PQnWqs99FlYl9wBbShrXWSBpT0kfAQYCy1KiOATYNR2ykqzV0Oku4DPK5o1A0hBJ7wJ+DRyrbF7l7YCPAUTEK8BLqQ7IBvur++MqaTNgWETMBM5PsW2X6v586qhH0gfTW+4F/iaV7UF2yWkdEfEa2ai035W0RTq2TdInyDqcD0r9D/2Ak1OM3ZVD1ur4DLCbpPPrfZ4eegJok7R/inlzSX9RYn3WJG5ZWGVEREj6OHBl+oFbDTwDnANcD9yRLofMIQ0VHRF/lPRrSY+RXTL5oqQ/B36bfrNXkfUjPCRpKtnloxfILqO8kqoeC/xL6mR+Cjg9J9R+wL+nS1gCJkXEy5IuAa4E5qeE8jRZUroK+KGkRWTTqc7t5rxfBf4RWChpNVmr5msRsVTSBLL5FAT8LCJuB+iuPP1t3pJ0MjBV0sqI6PU7xiLiDUknAJPS36M/2d9gQW/XZc3lUWetZUjaLiJWpaRwLzAu0rzYZlafWxbWSiZL2p2sr2OKE4VZcW5ZmJlZLndwm5lZLicLMzPL5WRhZma5nCzMzCyXk4WZmeX6H8NPRDAqHC/GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(['1', '2', '3'], wrong_dict.values())\n",
    "plt.xlabel('Categorised Cook Time')\n",
    "plt.ylabel('Number of Wrong Predictions')\n",
    "wrong_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
